# Name -  Harsh Tomar And PN Tejeshwar sarma
# Roll No -  2110110233 And 2110110361


import math
import os
from collections import defaultdict

class VectorSpaceModel:
    def __init__(self):
        self.dictionary = {}  
        self.doc_lengths = {}  
        self.documents = {}  
        self.N = 0  # Total number of documents
    
    def add_document(self, doc_id, content):
        # Add document to the system and update the dictionary and postings
        self.documents[doc_id] = content
        term_counts = defaultdict(int)
        
        # Tokenization and counting term frequencies
        for term in content.split():
            term_counts[term.lower()] += 1
        
        # Update dictionary and postings list
        for term, count in term_counts.items():
            if term not in self.dictionary:
                self.dictionary[term] = [0, []]  
            self.dictionary[term][0] += 1  
            self.dictionary[term][1].append((doc_id, count))  
        
        # Calculate document length
        doc_length = sum((1 + math.log10(freq))**2 for freq in term_counts.values())  
        self.doc_lengths[doc_id] = math.sqrt(doc_length)
        self.N += 1

    def compute_query_vector(self, query):
        # Compute tf-idf vector for the query
        term_counts = defaultdict(int)
        query_vector = {}
        
        # Tokenize query and count term frequencies
        for term in query.split():
            term_counts[term.lower()] += 1
        
        # Calculate tf-idf weights
        for term, count in term_counts.items():
            if term in self.dictionary:
                doc_freq = self.dictionary[term][0]
                idf = math.log10(self.N / doc_freq)  
                query_vector[term] = (1 + math.log10(count)) * idf 
        
        return query_vector

    def rank_documents(self, query_vector):
        # Compute cosine similarity between query and each document
        scores = defaultdict(float)
        
        for term, weight in query_vector.items():
            if term in self.dictionary:
                postings_list = self.dictionary[term][1]
                for doc_id, term_freq in postings_list:
                    doc_weight = 1 + math.log10(term_freq)  
                    scores[doc_id] += weight * doc_weight
        
        # Normalize scores by document lengths
        for doc_id in scores:
            scores[doc_id] /= self.doc_lengths[doc_id]
        
        # Return top 10 documents sorted by score
        return sorted(scores.items(), key=lambda x: (-x[1], x[0]))[:10]

    def search(self, query):
        query_vector = self.compute_query_vector(query)
        return self.rank_documents(query_vector)

    def load_documents_from_directory(self, directory_path):
        # Read documents from a given directory and add to the model
        for filename in os.listdir(directory_path):
            if filename.endswith(".txt"):  # Process only text files
                file_path = os.path.join(directory_path, filename)
                with open(file_path, 'r', encoding='utf-8') as file:
                    content = file.read()
                    doc_id = filename  # Use filename as document ID
                    self.add_document(doc_id, content)
        print(f"Loaded {self.N} documents from {directory_path}.")


# Initialize the model
vsm = VectorSpaceModel()

# Specify the directory path for the documents
directory_path = r"C:\Users\Harsh\Desktop\dddddddddddddddddddddddd\Corpus-20230203T210935Z-001\Corpus"

# Load documents from the specified directory
vsm.load_documents_from_directory(directory_path)

# Get query from the user
user_query = input("Enter your query: ")

# Search and display results
results = vsm.search(user_query)

# Print results
print("\nTop 10 relevant documents:")
for doc_id, score in results:
    print(f"Document ID: {doc_id}, Score: {score:.4f}")
